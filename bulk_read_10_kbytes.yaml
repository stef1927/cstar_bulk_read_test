keyspace: bulk_read

keyspace_definition: |

  CREATE KEYSPACE bulk_read WITH replication = { 'class': 'SimpleStrategy', 'replication_factor':1 };

# A table with a partitions of 100 rows where each row has two integer keys and two values of 50 bytes each
# Compaction and compression are also disabled so we can better benchmark the read operations
table: data_10_kbytes

table_definition:

  CREATE TABLE data_10_kbytes (
    pk int,
    c1 int,
    v1 text,
    v2 text,
    PRIMARY KEY(pk, c1));


columnspec:
  - name: pk

  - name: c1
    cluster: fixed(1)

  - name: v1
    size: fixed(5120)

  - name: v2
    size: fixed(5120)

insert:
  partitions: fixed(1)  # the number of partitions
  select: fixed(1)/1  # the probability of visiting any row in the partition
  batchtype: UNLOGGED

queries:
  single_part_query:
    cql: select * from data_10_kbytes where pk = ?
    fields: samerow

token_range_queries:
  all_columns_tr_query: 
    columns: '*'
    page_size: 100

  c1_v1_v2_tr_query:
    columns: c1, v1, v2
    page_size: 100

  v1_v2_tr_query:
    columns: v1, v2
    page_size: 100
