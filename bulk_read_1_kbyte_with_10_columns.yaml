keyspace: bulk_read

keyspace_definition: |

  CREATE KEYSPACE bulk_read WITH replication = { 'class': 'SimpleStrategy', 'replication_factor':1 };

# A table with a partitions of 100 rows where each row has two integer keys and two values of 50 bytes each
# Compaction and compression are also disabled so we can better benchmark the read operations
table: data_1_kbyte

table_definition:

  CREATE TABLE data_1_kbyte_10_columns (
    pk int,
    c1 int,
    v1 text,
    v2 text,
    v3 text,
    v4 text,
    v5 text,
    v6 text,
    v7 text,
    v8 text,
    v9 text,
    v10 text,
    PRIMARY KEY(pk, c1));


columnspec:
  - name: pk

  - name: c1
    cluster: fixed(1)

  - name: v1
    size: fixed(10)

  - name: v2
    size: fixed(10)

  - name: v3
    size: fixed(10)

  - name: v4
    size: fixed(10)

  - name: v5
    size: fixed(10)

  - name: v6
    size: fixed(10)

  - name: v7
    size: fixed(10)

  - name: v8
    size: fixed(10)

  - name: v9
    size: fixed(10)

  - name: v10
    size: fixed(10)

insert:
  partitions: fixed(1)  # the number of partitions
  select: fixed(1)/1  # the probability of visiting any row in the partition
  batchtype: UNLOGGED

queries:
  single_part_query:
    cql: select * from data_1_kbyte where pk = ?
    fields: samerow

token_range_queries:
  all_columns_tr_query: 
    columns: '*'
    page_size: 1000

  c1_v1_v2_tr_query:
    columns: c1, v1, v2
    page_size: 1000

  v1_v2_tr_query:
    columns: v1, v2
    page_size: 1000
